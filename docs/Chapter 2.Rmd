---
title: "Chapter 2"
header-includes:
   - \usepackage[lined,commentsnumbered]{algorithm2e}
output:
  rmarkdown::tufte_handout: default
  md_document:
    variant: markdown_github
---
```{r echo=FALSE}
options(digits = 3)

PlotTsAndDensity <- function (x) {
  #par(mfrow = c(1, 2))
  plot.ts(x, xlab = NULL, ylab = NULL)
  hist(x, breaks=30, freq = F, main=NULL, xlab = NULL, ylab = NULL)
  lines(density(x, na.rm = T, from = 0, to = max(x, na.rm = T)))
}
```

# HMM Model Derivation

## Independent Mixture Model

This section will outline the derivation of the HMM for univariate poisson observed data. We will use a toy example in order to illustrate the derivation.

An independent mixture model consists of $m < \infty$ component distributions with probability functions $p_i$ for $i \in {1, ... , m}$ and a “mixing distribution”. The mixing is performed by a discrete random variable $C$:
$$C =
  \begin{cases}
   1        & \text{with probability } \delta_1 \\
   \vdots   & \vdots \\
   i        & \text{with probability } \delta_i \\
   \vdots   & \vdots \\
   m        & \text{with probability } \delta_m = \sum_{i=1}^{m-1} \delta_i
  \end{cases}$$

Thus $Pr(C=i)=\delta_i$ must obey $0 < \delta_i < 1$ and that  $\sum_{i=1}^m \delta_i = 1$

For a discrete random variable X described by a mixture model consisting of $m$ components it holds that:

$$p(X) = \sum_{i=1}^m \delta_i p_i(X) \implies PR(X = x) = \sum_{i=1}^m Pr(X = x|C = i)$$

To estimate the parameters $\theta$ of the mixture distribution via ML estimation we maximize the combined likelihood of the components:

$$L(\theta_1,...,\theta_m,\delta_1,...,\delta_m|x_1,...,x_n) = \prod_{j=1}^n \sum_{i=1}^m \delta_i p_i(x_j, \theta_i)$$

For the example where $m = 2$ and the component distributions are poisson with parameters $\lambda_1$ and $\lambda_2$ the likelihood equation is as follows:

$$L(\lambda_1,\lambda_2,\delta_1,\delta_2 | x_1,...,x_n) = \prod_{j=1}^n \Bigg( \delta_1 \frac{\lambda_1^{x_j} e^{-\lambda_1}}{x_j !} + \delta_2 \frac{\lambda_2^{x_j} e^{-\lambda_2}}{x_j !} \Bigg)$$

In R this could be implemented naively as follows:

```{r}
lambdas = c(3, 15)
deltas = c(0.3, 0.7)
cdf = cumsum(deltas)
unifvec = runif(100)
d1 = rpois(sum(unifvec < cdf[1]),lambdas[1])
d2 = rpois(sum(unifvec >= cdf[1]),lambdas[2])
x = c(d1,d2) 
```

This code generates a series of x values according to a mixture of two poisson distributions with $\lambda_1=`r lambdas[1]`, \lambda_2=`r lambdas[2]`, \delta_1=`r deltas[1]`$ and $\delta_2=`r deltas[2]`$

We can see from both the following plots of the time series and the histograms (with fitted density) the data appears to conform to two separate distributions, or states:  

```{r echo=FALSE, fig.fullwidth = FALSE}
PlotTsAndDensity(x)
```

Before maximisiming the negative log-likelihood, the final step is that we must apply a transformation of the parameters in order to fulfill the requirements that $\sum_i \delta_i = 1$, $\delta_i > 0$ and $\lambda_i > 0$ for all $i$. This is achieved by log-transforming $\lambda$ and logit transforming $\delta$.

$$\text{Log-transform }\quad \eta_i = log \lambda_i, i = 1,...,m$$
$$\text{Logit-transform }\quad \tau_i = log \Bigg( \frac{\delta_1}{1 - \delta_2}\Bigg)$$

In R:
```{r eval=TRUE}
logit <- function(delta2) log(delta2/(1-delta2))

eta = log(lambdas)
tau = logit(deltas[2])
```

After the maximisation has occured the original parameters can be recovered by the inverse transformations:

$$\text{exp-transform }\quad \lambda_i = e^{\eta_i}, i = 1,...,m$$
$$\text{inverse logit }\quad \delta_2 = \frac{e^{\tau}}{1 + e^{\tau}}$$

and additionally $\delta_1 = 1 - delta_2$

```{r eval=TRUE}
invlogit <- function(tau) exp(tau)/(1+exp(tau))

lambdas = exp(eta)
delta2 = invlogit(tau)
delta1 = 1 - delta2
```

Now we have all the building blocks to maximise the negative log-likelihood for a two-state mixture distribution:

```{r warning=FALSE}
f <- function(theta,data) {
  eta <- theta[1:2]
  tau <- theta[3]
  lambdas = exp(eta) 
  delta2 = invlogit(tau)
  delta1 = 1-delta2

  L = delta1*dpois(data,lambdas[1]) + delta2*dpois(data,lambdas[2])
  -sum(log(L))
}

#use the 25% and 75%  quantiles of the data as a guess for lambdas
quantiles <- quantile(x)
lambdaGuess = c(quantiles[2],quantiles[4]) 

deltaGuess = 0.1

# Optimize using nlm
theta <- c(log(lambdaGuess), logit(deltaGuess))
res = nlm(f, theta, data = x)

# Back transform results
lambda1Hat = exp(res$estimate[1])
lambda2Hat = exp(res$estimate[2])

delta2Hat = invlogit(res$estimate[3])
delta1Hat = 1-delta2Hat
```

Estimated values:

$$\boldsymbol{\lambda} = 
\begin{pmatrix}
 `r lambdas[1]` \\
 `r lambdas[2]`
\end{pmatrix} \qquad
\boldsymbol{\hat{\lambda}} = 
\begin{pmatrix}
 `r lambda1Hat` \\
 `r lambda2Hat`
\end{pmatrix}$$

$$\boldsymbol{\delta} = 
\begin{pmatrix}
 `r deltas[1]` \\
 `r deltas[2]`
\end{pmatrix} \qquad
\boldsymbol{\hat{\delta}} = 
\begin{pmatrix}
 `r delta1Hat` \\
 `r delta2Hat`
\end{pmatrix}$$

The mixture distribution parameters appear to be estimated satisfactorily.

The next step is to introduce into the model a way of capturing the transition behaviour between the states over time.

## Markov switching process

The independent mixture model is used to cater for the overdispersion noticed in some time series data. The second feature often found is that they exhibit serial dependece between the observations. This dependence is identified via the autocorrelation function of the data. To cater for this we model the dependence between the mixtures by introducing a Markov process. With this building block we will have completely defined the hidden Markov model. 

If we define $\{C_t : t = 1,2, \dots \}$ as the unbserved hidden states, and $\{X_t : t = 1,2, \dots \}$ as the observed data points, we can say a hidden Markov is a dependent mixture where:

$$Pr(C_t = i | C^{(t-1)}) = Pr(C_t = i | C_{t-1}), t = 2,3,\dots$$
$$Pr(X_t = x | X^{(t-1)}, C^{(t)}) = Pr(X_t = x | C_t), t \in \mathbb{N}$$

As shown in the directed graph below, this is saying that when $C_t$ is known the distribution of $X_t$ only depends on $C_t$

\begin{figure}
  \includegraphics{images/hmm-states}
\end{figure}

For discrete distributions we can define the m-state dependant distribution function as:

$$p_i(X) = Pr(X_t = x | C_t = i), i,2,\dots,m$$

Which is simply the conditional probability of observing $x$ at time $t$ when $C$ is in state $i$.

Additionally we can define the unconditional probability of being in state $i$ at time $t$ as:

$$u_i(t) = Pr(C_t = i), t = 1,\dots,T$$

We will often want to calculate the marginal distribution of $X$. This can be achieved by summing over the states and using the hidden state and state-dependent distributions we defined earlier:

\begin{align}
 \begin{aligned}\nonumber  
    Pr(X_t = x) &= \sum_{i=1}^m Pr(C_t = i) Pr(X_t = x | C_t = i) \\
                &= \sum_{i=1}^m u_i(t) p_i(x) \\
                &= \begin{pmatrix}
                     u_1(t),\dots,u_m(t) 
                   \end{pmatrix}
                   \begin{pmatrix}
                     p_1(x) &        & 0 \\
                            & \ddots &   \\
                     0      &        & p_m(x) 
                   \end{pmatrix}
                   \begin{pmatrix}
                     1 \\
                     \vdots \\
                     1 
                   \end{pmatrix} \\
                &= \mathbf{u}(t) \mathbf{P}(x) \mathbf{1'}
 \end{aligned}
 \end{align}
 
$\mathbf{u}(t)$ is the distribution of the hidden states, and $\mathbf{P}(x)$ is the state-dependent distribution of the observations. $\mathbf{u}(1)$ is defined as the initial distribution of the Markov chain.

Next we introduce the transition probability matrix $\boldsymbol{\Gamma}(t)$ which is the $m \times m$ matrix of transition probabilities at state $t$:

$$\boldsymbol{\Gamma}(1) = \begin{pmatrix}
                             \gamma_{11} & \cdots & \gamma_{1m} \\
                             \vdots      & \ddots & \vdots  \\
                             \gamma_{m1} & \cdots & \gamma_{mm}
                           \end{pmatrix}$$

$$\gamma_{ij}(t) = Pr(C_{s+t} = j | C_s = i)$$

Because the Markov chain satisfies the Chapman-Kolmogorov equations we can say that $\mathbf{u}(t) = \mathbf{u}(1) \boldsymbol{\Gamma}^{t-1}$ ($\boldsymbol{\Gamma}$ is shorthand for $\boldsymbol{\Gamma}(1)$) and hence it follows that: 

$$Pr(X_t = x) = \mathbf{u}(1) \boldsymbol{\Gamma}^{t-1} \mathbf{P}(x) \mathbf{1'}$$

If the Markov chain can be shown to be stationary with stationary distribution $\boldsymbol{\delta}$, because $\boldsymbol{\delta} \boldsymbol{\Gamma}^{t-1} = \boldsymbol{\delta}$ for all $t$ we get:

$$Pr(X_t = x) = \boldsymbol{\delta} \mathbf{P}(x) \mathbf{1'}$$

