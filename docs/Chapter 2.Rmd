---
title: "Chapter 2"
header-includes:
   - \usepackage[lined,commentsnumbered]{algorithm2e}
output:
  rmarkdown::tufte_handout: default
  word_document: default
bibliography: library.bib
csl: harvard1.csl
---

```{r echo=FALSE}
options(digits = 3)

PlotTsAndDensity <- function (x) {
  #par(mfrow = c(1, 2))
  plot.ts(x, xlab = NULL, ylab = NULL)
  hist(x, breaks=30, freq = F, main=NULL, xlab = NULL, ylab = NULL)
  lines(density(x, na.rm = T, from = 0, to = max(x, na.rm = T)))
}
```

# HMM Model Derivation

## Independent Mixture Model

This section will outline the derivation of the HMM for univariate poisson observed data. We will use a toy example in order to illustrate the derivation.

An independent mixture model consists of $m$ component distributions with probability functions $p_i$ for $i \in {1, ... , m}$ and a “mixing distribution”. The mixing is performed by a discrete random variable $C$:
$$C =
  \begin{cases}
   1        & \text{with probability } \delta_1 \\
   \vdots   & \vdots \\
   i        & \text{with probability } \delta_i \\
   \vdots   & \vdots \\
   m        & \text{with probability } \delta_m = \sum_{i=1}^{m-1} \delta_i
  \end{cases}$$

Thus $Pr(C=i)=\delta_i$ must obey $0 < \delta_i < 1$ and that  $\sum_{i=1}^m \delta_i = 1$

For a discrete random variable X described by a mixture model consisting of $m$ components it holds that:

$$p(X) = \sum_{i=1}^m \delta_i p_i(X) \implies PR(X = x) = \sum_{i=1}^m Pr(X = x|C = i)$$

To estimate the parameters $\theta$ of the mixture distribution via ML estimation we maximize the combined likelihood of the components:

$$L(\theta_1,...,\theta_m,\delta_1,...,\delta_m|x_1,...,x_n) = \prod_{j=1}^n \sum_{i=1}^m \delta_i p_i(x_j, \theta_i)$$

For the example where $m = 2$ and the component distributions are poisson with parameters $\lambda_1$ and $\lambda_2$ the likelihood equation is as follows:

$$L(\lambda_1,\lambda_2,\delta_1,\delta_2 | x_1,...,x_n) = \prod_{j=1}^n \Bigg( \delta_1 \frac{\lambda_1^{x_j} e^{-\lambda_1}}{x_j !} + \delta_2 \frac{\lambda_2^{x_j} e^{-\lambda_2}}{x_j !} \Bigg)$$

In R this could be implemented naively as follows:

```{r}
lambdas = c(3, 15)
deltas = c(0.3, 0.7)
cdf = cumsum(deltas)
unifvec = runif(100)
d1 = rpois(sum(unifvec < cdf[1]),lambdas[1])
d2 = rpois(sum(unifvec >= cdf[1]),lambdas[2])
x = c(d1,d2) 
```

This code generates a series of x values according to a mixture of two poisson distributions with $\lambda_1=`r lambdas[1]`, \lambda_2=`r lambdas[2]`, \delta_1=`r deltas[1]`$ and $\delta_2=`r deltas[2]`$

We can see from both the following plots of the time series and the histograms (with fitted density) the data appears to conform to two separate distributions, or states:  

```{r echo=FALSE, fig.fullwidth = FALSE}
PlotTsAndDensity(x)
```

Before maximisiming the negative log-likelihood, the final step is that we must apply a transformation of the parameters in order to fulfill the requirements that $\sum_i \delta_i = 1$, $\delta_i > 0$ and $\lambda_i > 0$ for all $i$. This is achieved by log-transforming $\lambda$ and logit transforming $\delta$.

$$\text{Log-transform }\quad \eta_i = log \lambda_i, i = 1,...,m$$
$$\text{Logit-transform }\quad \tau_i = log \Bigg( \frac{\delta_1}{1 - \delta_2}\Bigg)$$

In R:
```{r eval=TRUE}
logit <- function(delta2) log(delta2/(1-delta2))

eta = log(lambdas)
tau = logit(deltas[2])
```

After the maximisation has occured the original parameters can be recovered by the inverse transformations:

$$\text{exp-transform }\quad \lambda_i = e^{\eta_i}, i = 1,...,m$$
$$\text{inverse logit }\quad \delta_2 = \frac{e^{\tau}}{1 + e^{\tau}}$$

and additionally $\delta_1 = 1 - \delta_2$

```{r eval=TRUE}
invlogit <- function(tau) exp(tau)/(1+exp(tau))

lambdas = exp(eta)
delta2 = invlogit(tau)
delta1 = 1 - delta2
```

Now we have all the building blocks to maximise the negative log-likelihood for a two-state mixture distribution:

```{r warning=FALSE, cache=TRUE}
f <- function(theta,data) {
  eta <- theta[1:2]
  tau <- theta[3]
  lambdas = exp(eta) 
  delta2 = invlogit(tau)
  delta1 = 1-delta2

  L = delta1*dpois(data,lambdas[1]) + delta2*dpois(data,lambdas[2])
  -sum(log(L))
}

#use the 25% and 75%  quantiles of the data as a guess for lambdas
quantiles <- quantile(x)
lambdaGuess = c(quantiles[2],quantiles[4]) 

deltaGuess = 0.1

# Optimize using nlm
theta <- c(log(lambdaGuess), logit(deltaGuess))
res = nlm(f, theta, data = x)

# Back transform results
lambda1Hat = exp(res$estimate[1])
lambda2Hat = exp(res$estimate[2])

delta2Hat = invlogit(res$estimate[3])
delta1Hat = 1-delta2Hat
```

Estimated values:

$$\boldsymbol{\lambda} = 
\begin{pmatrix}
 `r lambdas[1]` \\
 `r lambdas[2]`
\end{pmatrix} \qquad
\boldsymbol{\hat{\lambda}} = 
\begin{pmatrix}
 `r lambda1Hat` \\
 `r lambda2Hat`
\end{pmatrix}$$

$$\boldsymbol{\delta} = 
\begin{pmatrix}
 `r deltas[1]` \\
 `r deltas[2]`
\end{pmatrix} \qquad
\boldsymbol{\hat{\delta}} = 
\begin{pmatrix}
 `r delta1Hat` \\
 `r delta2Hat`
\end{pmatrix}$$

The mixture distribution parameters appear to be estimated satisfactorily.

The next step is to introduce into the model a way of capturing the transition behaviour between the states over time.

## Markov switching process

The independent mixture model is used to cater for the overdispersion noticed in some time series data. The second feature often found is that they exhibit serial dependece between the observations. This dependence is identified via the autocorrelation function of the data. To cater for this we model the dependence between the mixtures by introducing a Markov process. With this building block we will have completely defined the hidden Markov model. 

If we define $\{C_t : t = 1,2, \dots \}$ as the unbserved hidden states, and $\{X_t : t = 1,2, \dots \}$ as the observed data points, we can say a hidden Markov is a dependent mixture where:

$$Pr(C_t = i | C^{(t-1)}) = Pr(C_t = i | C_{t-1}), t = 2,3,\dots$$
$$Pr(X_t = x | X^{(t-1)}, C^{(t)}) = Pr(X_t = x | C_t), t \in \mathbb{N}$$

As shown in the directed graph below, this is saying that when $C_t$ is known the distribution of $X_t$ only depends on $C_t$

\begin{figure}
  \includegraphics{images/hmm-states}
\end{figure}

For discrete distributions we can define the m-state dependant distribution function as:

\begin{equation} \label{eq:dependantDist}
  p_i(X) = Pr(X_t = x | C_t = i), i,2,\dots,m
\end{equation}

Which is simply the conditional probability of observing $x$ at time $t$ when $C$ is in state $i$.

Additionally we can define the unconditional probability of being in state $i$ at time $t$ as:

\begin{equation} \label{eq:stateDist}
  u_i(t) = Pr(C_t = i), t = 1,\dots,T
\end{equation}

We will often want to calculate the marginal distribution of $X$. This can be achieved by summing over the states and using the hidden state $\eqref{eq:stateDist}$ and state-dependent $\eqref{eq:dependantDist}$ distributions:

\begin{align}
 \begin{aligned}\nonumber  
    Pr(X_t = x) &= \sum_{i=1}^m Pr(C_t = i) Pr(X_t = x | C_t = i) \\
                &= \sum_{i=1}^m u_i(t) p_i(x) \\
                &= \begin{pmatrix}
                     u_1(t),\dots,u_m(t) 
                   \end{pmatrix}
                   \begin{pmatrix}
                     p_1(x) &        & 0 \\
                            & \ddots &   \\
                     0      &        & p_m(x) 
                   \end{pmatrix}
                   \begin{pmatrix}
                     1 \\
                     \vdots \\
                     1 
                   \end{pmatrix} \\
                &= \mathbf{u}(t) \mathbf{P}(x) \mathbf{1'}
 \end{aligned}
 \end{align}
 
$\mathbf{u}(t)$ is the distribution of the hidden states, and $\mathbf{P}(x)$ is the state-dependent distribution of the observations. $\mathbf{u}(1)$ is defined as the initial distribution of the Markov chain.

The diagonal matrix of conditional probabilities ${P}(x)$ defined as:
$$\mathbf{P}(x) = \begin{pmatrix}
                   p_1(x) &        & 0 \\
                          & \ddots &   \\
                   0      &        & p_m(x) 
                 \end{pmatrix}$$

Where for example: $\boldsymbol{\lambda} = \begin{pmatrix}
                           `r lambdas[1]` \\
                           `r lambdas[2]`
                         \end{pmatrix}$
$$\mathbf{P}(1) = \begin{pmatrix}
 \frac{e^{-`r lambdas[1]`} `r lambdas[1]`^1}{1!} & 0 \\
 0                     & \frac{e^{-`r lambdas[2]`} `r lambdas[2]`^1}{1!} 
\end{pmatrix} = 
\begin{pmatrix}
 `r dpois(1, lambdas[1])` & 0 \\
 0                        & `r dpois(1, lambdas[2])`
\end{pmatrix}$$

This can be implemented easily in R as:

```{r}
PMat <- function(x) diag(dpois(x = x, lambda = lambdas))

PMat(1)
```

Next we introduce the transition probability matrix $\boldsymbol{\Gamma}(t)$ which is the $m \times m$ matrix of transition probabilities at state $t$:

$$\boldsymbol{\Gamma}(1) = \begin{pmatrix}
                             \gamma_{11} & \cdots & \gamma_{1m} \\
                             \vdots      & \ddots & \vdots  \\
                             \gamma_{m1} & \cdots & \gamma_{mm}
                           \end{pmatrix}$$

$$\gamma_{ij}(t) = Pr(C_{s+t} = j | C_s = i)$$

Because the Markov chain satisfies the Chapman-Kolmogorov equations we can say that $\mathbf{u}(t) = \mathbf{u}(1) \boldsymbol{\Gamma}^{t-1}$ (where $\boldsymbol{\Gamma}$ is shorthand for $\boldsymbol{\Gamma}(1)$) and hence it follows that: 

\begin{equation} \label{eq:marginalNonStat}
  Pr(X_t = x) = \mathbf{u}(1) \boldsymbol{\Gamma}^{t-1} \mathbf{P}(x) \mathbf{1'}
\end{equation}

If the Markov chain can be shown to be stationary with stationary distribution $\boldsymbol{\delta}$, because $\boldsymbol{\delta} \boldsymbol{\Gamma}^{t-1} = \boldsymbol{\delta}$ for all $t$ we get:

\begin{equation} \label{eq:marginalStat}
  Pr(X_t = x) = \boldsymbol{\delta} \mathbf{P}(x) \mathbf{1'}
\end{equation}

It can be shown that if the stationary distribution exists then $\boldsymbol{\delta}$ can be found using the following calculation:

\begin{equation} \label{eq:stationary}
  \boldsymbol{\delta} (\mathbf{I}_m - \boldsymbol{\Gamma} + \mathbf{U}) = \mathbf{1}
\end{equation}

Where $\mathbf{I}_m$ is an $m \times m$ identity matrix and $\mathbf{U}$ is an $m \times m$ matrix of ones. This can be implemented simply in R as follows:


```{r}
statdist <- function(gamma){
  m = dim(gamma)[1]
  matrix(1,1,m) %*% solve(diag(1,m) - gamma + matrix(1,m,m))
}
```

To illustrate this concept, lets extend the example we used previously this time introducing a hypothetical transition matrix:

```{r}
gamma = matrix(c(0.9,0.1,0.4,0.6), nrow = 2, byrow = TRUE)
```

$$\boldsymbol{\lambda} = \begin{pmatrix}
                           `r lambdas[1]` \\
                           `r lambdas[2]`
                         \end{pmatrix} \qquad
\boldsymbol{\Gamma} = \begin{pmatrix}
                        `r gamma[1,1]` & `r gamma[1,2]` \\
                        `r gamma[2,1]` & `r gamma[2,2]`
                      \end{pmatrix}$$

We can now calculate the stationary distribution $\boldsymbol{\delta}$ using equation $\eqref{eq:stationary}$:

```{r}
delta = statdist(gamma)
```

$$\boldsymbol{\delta} = \begin{pmatrix}
                           `r delta[1]` \\
                           `r delta[2]`
                         \end{pmatrix} \qquad$$
                         
With which we can now calculate the marginal distribution $\eqref{eq:marginalStat}$, for example for $P(X = 1)$:

```{r}
x = 1
sum(delta %*% PMat(x))
```

## Calculating the Likelihood

The first step to calculate the likelihood function is to extend the univariate marginal distribution $\eqref{eq:marginalNonStat}$ to a bivariate distribution. @zucchini show that $\eqref{eq:marginalNonStat}$ can be extended so that:

$$Pr(X_t = v, X_{t+k} = w) = \mathbf{u}(t) \mathbf{P}(v) \boldsymbol{\Gamma}^k \mathbf{P}(w) \mathbf{1'}$$

While the equivalent for a stationary chain reduces to:

$$Pr(X_t = v, X_{t+k} = w) = \boldsymbol{\delta} \mathbf{P}(v) \boldsymbol{\Gamma}^k \mathbf{P}(w) \mathbf{1'}$$

This then can be generalised to a $T$-th order distribution and hence the likelihood for a set of observations $\mathbf{X}^{(T)} = (X_1,X_2,\dots,X_T)$ given the parameters of an HMM is:

$$L_T = \boldsymbol{\delta} \mathbf{P}(x_1) \boldsymbol{\Gamma} \mathbf{P}(x_2) \dots \boldsymbol{\Gamma} \mathbf{P}(x_T) \mathbf{1'}$$

A recursive algorithm can be defined to calculate the likelihood, first by defining the foward probability vector:

$$\boldsymbol{\alpha_t} = \boldsymbol{\delta} \mathbf{P}(x_1) \boldsymbol{\Gamma} \mathbf{P}(x_2) \dots \boldsymbol{\Gamma} \mathbf{P}(x_T)$$

From which the likelihood can now be recursively calculated:

\begin{align}
 \begin{aligned}\nonumber  
     \boldsymbol{\alpha_1} &= \boldsymbol{\delta} \mathbf{P}(x_1) \\
     \boldsymbol{\alpha_t} &= \boldsymbol{\alpha_{t-1}} \boldsymbol{\Gamma} \mathbf{P}(x_t) \qquad for \quad t = 2,3,\dots,T\\
     L_T                   &= \boldsymbol{\alpha_T} \mathbf{1'}
 \end{aligned}
 \end{align}

If $\boldsymbol{\delta}$ provided is in fact the stationary distribution of the Markov chain, then the recursive scheme becomes:

\begin{align}
 \begin{aligned}\nonumber  
     \boldsymbol{\alpha_0} &= \boldsymbol{\delta} \\
     \boldsymbol{\alpha_t} &= \boldsymbol{\alpha_{t-1}} \boldsymbol{\Gamma} \mathbf{P}(x_t) \qquad for \quad t = 1,2,\dots,T\\
     L_T                   &= \boldsymbol{\alpha_T} \mathbf{1'}
 \end{aligned}
 \end{align}
 
 With R implementation:

```{r}
pois.hmm.alpha <- function(x, gamma, delta = NULL)
{
  n = length(x)
  alpha = vector(mode="list", length=n)
  alpha0= statdist(gamma)
  
  for(t in 1:n)
  {
    if(t==1)
    {
      prevAlpha = alpha0
    }
    else
    {
      prevAlpha = alpha[[t-1]]
    }
    alpha[[t]] = prevAlpha %*% gamma %*% PMat(x[t])
  }
  return(alpha[[length(x)]])
}
```

The problem with this scheme however is that as $t$ increases, $\boldsymbol{\alpha_t}$ rapidly diminishes as it is the product of a large number of probabilities, and when implemented computationally, will be rounded to zero (a problem known as underflow). We can show that the calculation works for small $t$ however needs to be re-worked for any non-trivial time series.

As an example we can calculate $Pr(X_1 = 0, X_2 = 2, X_3 = 1)$, using the previously defined $\boldsymbol{\Gamma}$ and $\boldsymbol{\lambda}$ parameters: 
```{r}
x = c(0,2,1)
alpha = pois.hmm.alpha(x, gamma)
prob = sum(alpha)
prob
```
@durbin present a method of scaling the computations to mitigate this issue of underflow.
[@durbin]
[@durbin, pp.99]
[-@durbin]
[@durbin]

#References